{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of Multi Label Classification on the cars dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the required Libraries and statements to avoid warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import tree,linear_model,neighbors, datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, roc_curve, auc\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.exceptions import ConvergenceWarning, DataConversionWarning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warnings for clean output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the cars dataset and exploring the dataset to understand the variables and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('car.data',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.columns = ['buying','maint','doors',\n",
    "                     'persons','lug_boot','safety','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset has around 1728 records with 7 variable, the one 6 is the features and the 7 variable is the target variable (class) which needs to be classified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying maint  doors persons lug_boot safety  class\n",
       "count    1728  1728   1728    1728     1728   1728   1728\n",
       "unique      4     4      4       3        3      3      4\n",
       "top      high  high  5more    more      big   high  unacc\n",
       "freq      432   432    432     576      576    576   1210"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that all the featues have all the values so missing data treatment is not required, all the features are ordinal since they have 4 distinct classes which have order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the target variable from features so that the features can be pre processed before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cars.loc[:,'buying':'safety']\n",
    "features1 = features\n",
    "target = cars[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety\n",
       "0  vhigh  vhigh     2       2    small    low\n",
       "1  vhigh  vhigh     2       2    small    med\n",
       "2  vhigh  vhigh     2       2    small   high\n",
       "3  vhigh  vhigh     2       2      med    low\n",
       "4  vhigh  vhigh     2       2      med    med"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_one_hot = pd.get_dummies(features1, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>doors_4</th>\n",
       "      <th>doors_5more</th>\n",
       "      <th>persons_4</th>\n",
       "      <th>persons_more</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_low  buying_med  buying_vhigh  maint_low  maint_med  maint_vhigh  \\\n",
       "0           0           0             1          0          0            1   \n",
       "1           0           0             1          0          0            1   \n",
       "2           0           0             1          0          0            1   \n",
       "3           0           0             1          0          0            1   \n",
       "4           0           0             1          0          0            1   \n",
       "\n",
       "   doors_3  doors_4  doors_5more  persons_4  persons_more  lug_boot_med  \\\n",
       "0        0        0            0          0             0             0   \n",
       "1        0        0            0          0             0             0   \n",
       "2        0        0            0          0             0             0   \n",
       "3        0        0            0          0             0             1   \n",
       "4        0        0            0          0             0             1   \n",
       "\n",
       "   lug_boot_small  safety_low  safety_med  \n",
       "0               1           1           0  \n",
       "1               1           0           1  \n",
       "2               1           0           0  \n",
       "3               0           1           0  \n",
       "4               0           0           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0  unacc\n",
       "1  unacc\n",
       "2  unacc\n",
       "3  unacc\n",
       "4  unacc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnike\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "classes = {'unacc': 0,'acc': 1,'good':2,'vgood':3} \n",
    " \n",
    "target['class'] = [classes[item] for item in target['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1210\n",
       "1     384\n",
       "2      69\n",
       "3      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "features = enc.fit_transform(features)\n",
    "features = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5\n",
       "0  3.0  3.0  0.0  0.0  2.0  1.0\n",
       "1  3.0  3.0  0.0  0.0  2.0  2.0\n",
       "2  3.0  3.0  0.0  0.0  2.0  0.0\n",
       "3  3.0  3.0  0.0  0.0  1.0  1.0\n",
       "4  3.0  3.0  0.0  0.0  1.0  2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = ['buying','maint','doors',\n",
    "                     'persons','lug_boot','safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety\n",
       "0     3.0    3.0    0.0      0.0       2.0     1.0\n",
       "1     3.0    3.0    0.0      0.0       2.0     2.0\n",
       "2     3.0    3.0    0.0      0.0       2.0     0.0\n",
       "3     3.0    3.0    0.0      0.0       1.0     1.0\n",
       "4     3.0    3.0    0.0      0.0       1.0     2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that entire data is converted to numericals, we shall start with the modeling process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.30,random_state=45,stratify = target)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(features_one_hot, target, test_size=0.30,random_state=44,stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 847, 1: 269, 2: 48, 3: 45}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 363, 1: 115, 2: 21, 3: 20}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data is split in the required ratio and the class labels ratio is maintained hence, there is no need for stratified samplied. we can continue with random split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms like decision tree has many hyperparameters which we can tweak.Grid Search method from sklearn can be used so that we can test a lot of hyperparamters and do cross validation of each to get the best set of hyper parameters.\n",
    "Below is the code for decision tree hyperparameter optimization using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max_depth, min_samples in leaf and min_impurity_decrease hyperparameters is used for the model because max depth and min samples in leaf nodes should put a constraint on the tree growing full to the each individual node which would lead to overfitting and min_impurity_decrease is used to deal with underfitting because if a node is impurity with this threshold the try will try to split it and try to make the leaf nodes pure than the parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_depth': np.arange(3,7),'min_samples_leaf': np.arange(5,30),\"criterion\":[\"gini\",\"entropy\"],\"min_impurity_decrease\":[1e-07,1e-06,1e-05,1e-04,1e-03,1e-02,1e-01,1]}\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "grid_tree = tree.DecisionTreeClassifier(random_state=45)\n",
    "\n",
    "#Nested CV inner loop\n",
    "grid = GridSearchCV(grid_tree, tuned_parameters, cv = inner_cv, scoring='accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "#Nested CV outer loop\n",
    "nested_score = cross_val_score(grid, features, target, cv=outer_cv,scoring ='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 87.33% +/- 3.30%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'criterion': 'entropy', 'max_depth': 6, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 7}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=1e-07, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=45,\n",
      "            splitter='best')\n",
      "Confusion Matrix: - \n",
      " [[327  33   3   0]\n",
      " [  0  97  11   7]\n",
      " [  0  10   9   2]\n",
      " [  0   0   0  20]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       363\n",
      "           1       0.69      0.84      0.76       115\n",
      "           2       0.39      0.43      0.41        21\n",
      "           3       0.69      1.00      0.82        20\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       519\n",
      "   macro avg       0.69      0.79      0.73       519\n",
      "weighted avg       0.90      0.87      0.88       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid.best_estimator_)\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 87.33% +/- 3.30%** with a **precision of 90% and recall of 87%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 88%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_depth': np.arange(3,7),'min_samples_leaf': np.arange(5,30),\"criterion\":[\"gini\",\"entropy\"],\"min_impurity_decrease\":[1e-07,1e-06,1e-05,1e-04,1e-03,1e-02,1e-01,1]}\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "grid_tree = tree.DecisionTreeClassifier(random_state=44)\n",
    "\n",
    "#Nested CV inner loop\n",
    "grid = GridSearchCV(grid_tree, tuned_parameters, cv = inner_cv, scoring='accuracy')\n",
    "grid.fit(X1_train,y1_train)\n",
    "\n",
    "#Nested CV outer loop\n",
    "nested_score = cross_val_score(grid, features_one_hot, target, cv=outer_cv,scoring ='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 83.62% +/- 2.13%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'criterion': 'gini', 'max_depth': 6, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 6}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=1e-07, min_impurity_split=None,\n",
      "            min_samples_leaf=6, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=44,\n",
      "            splitter='best')\n",
      "Confusion Matrix: - \n",
      " [[328  35   0   0]\n",
      " [ 13  91  11   0]\n",
      " [  0  12   6   3]\n",
      " [  0  13   3   4]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       363\n",
      "           1       0.60      0.79      0.68       115\n",
      "           2       0.30      0.29      0.29        21\n",
      "           3       0.57      0.20      0.30        20\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       519\n",
      "   macro avg       0.61      0.55      0.55       519\n",
      "weighted avg       0.84      0.83      0.83       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid.best_estimator_)\n",
    "y1_pred = grid.best_estimator_.predict(X1_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y1_test, y1_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 83.62% +/- 2.13%** with a **precision of 84% and recall of 83%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 83%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-NN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is based on distances between data points, since we have ordinal variables we cannot say that difference between 1-2 is **not same** as 2-3 so for KNN we are running the one hot encoded version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors' : np.arange(1,30), 'weights' : ['uniform','distance']}\n",
    "\n",
    "grid_knn_clf = neighbors.KNeighborsClassifier()\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "#Nested CV innner loop\n",
    "grid_knn = GridSearchCV(grid_knn_clf, param_grid, cv = inner_cv, scoring='accuracy')\n",
    "grid_knn.fit(X1_train,y1_train)\n",
    "\n",
    "#Nested CV outer loop\n",
    "nested_score = cross_val_score(grid_knn, features_one_hot, target, cv=outer_cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 82.47% +/- 4.01%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'n_neighbors': 10, 'weights': 'distance'}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='distance')\n",
      "Confusion Matrix: - \n",
      " [[355   8   0   0]\n",
      " [ 39  74   2   0]\n",
      " [  9   8   3   1]\n",
      " [  7   5   2   6]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       363\n",
      "           1       0.78      0.64      0.70       115\n",
      "           2       0.43      0.14      0.21        21\n",
      "           3       0.86      0.30      0.44        20\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       519\n",
      "   macro avg       0.73      0.52      0.57       519\n",
      "weighted avg       0.83      0.84      0.82       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_knn.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_knn.best_estimator_)\n",
    "y1_pred = grid_knn.best_estimator_.predict(X1_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y1_test, y1_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 82.47% +/- 4.01%** with a **precision of 83% and recall of 84%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 82%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {\n",
    "               'C':[1e-4,0.001,.009,0.01,.09,1,5,10,25,100,1000,1e4],\n",
    "               'multi_class' : ['multinomial'],\n",
    "              'solver': ['lbfgs']}\n",
    "\n",
    "grid_log_clf = linear_model.LogisticRegression(random_state=45)\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_logit = GridSearchCV(grid_log_clf, grid_values, cv = inner_cv, scoring='accuracy')\n",
    "grid_logit.fit(X_train,y_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_logit, features, target, cv=outer_cv,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 70.14% +/- 4.61%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'C': 0.09, 'multi_class': 'multinomial', 'solver': 'lbfgs'}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " LogisticRegression(C=0.09, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=45, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Confusion Matrix: - \n",
      " [[336  27   0   0]\n",
      " [ 91  24   0   0]\n",
      " [ 19   2   0   0]\n",
      " [ 14   6   0   0]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       363\n",
      "           1       0.41      0.21      0.28       115\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.00      0.00      0.00        20\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       519\n",
      "   macro avg       0.28      0.28      0.27       519\n",
      "weighted avg       0.60      0.69      0.63       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnike\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_logit.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_logit.best_estimator_)\n",
    "y_pred = grid_logit.best_estimator_.predict(X_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 70.14% +/- 4.61%** with a **precision of 60% and recall of 69%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 63%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'penalty': ['l1', 'l2'], \\\n",
    "               'C':[1e-4,0.001,.009,0.01,.09,1,5,10,25,100,1000,1e4],\n",
    "               'multi_class' : ['multinomial'],\n",
    "              'solver': ['saga']}\n",
    "\n",
    "grid_log_clf = linear_model.LogisticRegression(random_state=44)\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_logit = GridSearchCV(grid_log_clf, grid_values, cv = inner_cv, scoring='accuracy')\n",
    "grid_logit.fit(X1_train,y1_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_logit, features_one_hot, target, cv=outer_cv,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 92.82% +/- 2.20%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'C': 100, 'multi_class': 'multinomial', 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l1', random_state=44, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Confusion Matrix: - \n",
      " [[353   9   1   0]\n",
      " [ 21  91   1   2]\n",
      " [  0   2  14   5]\n",
      " [  0   0   1  19]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       363\n",
      "           1       0.89      0.79      0.84       115\n",
      "           2       0.82      0.67      0.74        21\n",
      "           3       0.73      0.95      0.83        20\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       519\n",
      "   macro avg       0.85      0.85      0.84       519\n",
      "weighted avg       0.92      0.92      0.92       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_logit.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_logit.best_estimator_)\n",
    "y1_pred = grid_logit.best_estimator_.predict(X1_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y1_test, y1_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 92.82% +/- 2.20%** with a **precision of 92% and recall of 92%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 92%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'alpha' : [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "grid_NB_clf = MultinomialNB()\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_NB = GridSearchCV(grid_NB_clf, grid_values, cv = inner_cv, scoring='accuracy')\n",
    "grid_NB.fit(X_train,y_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_NB, features, target, cv=outer_cv,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 70.08% +/- 4.55%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'alpha': 1}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
      "Confusion Matrix: - \n",
      " [[363   0   0   0]\n",
      " [113   2   0   0]\n",
      " [ 21   0   0   0]\n",
      " [ 20   0   0   0]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       363\n",
      "           1       1.00      0.02      0.03       115\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.00      0.00      0.00        20\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       519\n",
      "   macro avg       0.43      0.25      0.21       519\n",
      "weighted avg       0.71      0.70      0.58       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnike\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_NB.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_NB.best_estimator_)\n",
    "y_pred = grid_NB.best_estimator_.predict(X_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 70.08% +/- 4.55%** with a **precision of 71% and recall of 70%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 58%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'alpha' : [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "grid_NB_clf = MultinomialNB()\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_NB = GridSearchCV(grid_NB_clf, grid_values, cv = inner_cv, scoring='accuracy')\n",
    "grid_NB.fit(X1_train,y1_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_NB, features_one_hot, target, cv=outer_cv,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 73.78% +/- 5.51%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'alpha': 1}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
      "Confusion Matrix: - \n",
      " [[360   3   0   0]\n",
      " [ 87  28   0   0]\n",
      " [ 13   8   0   0]\n",
      " [ 16   4   0   0]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       363\n",
      "           1       0.65      0.24      0.35       115\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.00      0.00      0.00        20\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       519\n",
      "   macro avg       0.35      0.31      0.30       519\n",
      "weighted avg       0.67      0.75      0.68       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnike\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_NB.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_NB.best_estimator_)\n",
    "y1_pred = grid_NB.best_estimator_.predict(X1_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y1_test, y1_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 73.78% +/- 5.51%** with a **precision of 67% and recall of 75%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 68%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'kernel':['linear','rbf'],'C': [0.01, 0.1, 1, 10, 100], 'gamma' :[0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid_svc_clf= SVC(random_state = 45)\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_svm = GridSearchCV(grid_svc_clf, param_grid, cv = inner_cv, scoring='accuracy')\n",
    "grid_svm.fit(X_train,y_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_svm, features, target, cv=outer_cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 99.25% +/- 0.76%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=45, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Confusion Matrix: - \n",
      " [[360   3   0   0]\n",
      " [  0 115   0   0]\n",
      " [  0   0  21   0]\n",
      " [  0   1   0  19]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       363\n",
      "           1       0.97      1.00      0.98       115\n",
      "           2       1.00      1.00      1.00        21\n",
      "           3       1.00      0.95      0.97        20\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       519\n",
      "   macro avg       0.99      0.99      0.99       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_svm.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_svm.best_estimator_)\n",
    "y_pred = grid_svm.best_estimator_.predict(X_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 99.25% +/- 0.76%** with a **precision of 99% and recall of 99%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 99%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'kernel':['linear','rbf'],'C': [0.01, 0.1, 1, 10, 100], 'gamma' :[0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid_svc_clf= SVC(random_state = 45)\n",
    "\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=45)\n",
    "\n",
    "grid_svm = GridSearchCV(grid_svc_clf, param_grid, cv = inner_cv, scoring='accuracy')\n",
    "grid_svm.fit(X1_train,y1_train)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_score = cross_val_score(grid_svm, features_one_hot, target, cv=outer_cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nested CV with grid search,accuracy: 99.25% +/- 1.15%\n",
      "\n",
      "The best hyper-parameters to get this accuracy is :-\n",
      " {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "The best decision tree classifier is :-\n",
      " SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=45, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Confusion Matrix: - \n",
      " [[362   1   0   0]\n",
      " [  1 114   0   0]\n",
      " [  0   0  21   0]\n",
      " [  0   0   0  20]]\n",
      "\n",
      "Classification Report: - \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       363\n",
      "           1       0.99      0.99      0.99       115\n",
      "           2       1.00      1.00      1.00        21\n",
      "           3       1.00      1.00      1.00        20\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       519\n",
      "   macro avg       1.00      1.00      1.00       519\n",
      "weighted avg       1.00      1.00      1.00       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy with +/- 2 std deviations\n",
    "print(\"Using Nested CV with grid search,accuracy: {0:.2%} +/- {1:.2%}\".format(nested_score.mean(), nested_score.std() * 2))\n",
    "print()\n",
    "print (\"The best hyper-parameters to get this accuracy is :-\\n\", grid_svm.best_params_)\n",
    "print()\n",
    "print (\"The best decision tree classifier is :-\\n\", grid_svm.best_estimator_)\n",
    "y1_pred = grid_svm.best_estimator_.predict(X1_test)\n",
    "\n",
    "#Goodness Measures confusion matrix and other measures like accuracy, precision,recall\n",
    "print(\"Confusion Matrix: - \\n\",confusion_matrix(y1_test, y1_pred))\n",
    "print()\n",
    "print(\"Classification Report: - \\n\",classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Goodness**\n",
    "\n",
    "The class distribution is 1210 unacceptable, 384 acceptable ,69 good, 65 very good cars, the decision tree classifier without one hot encoding gives an **Accuracy of 99.25% +/- 1.15%** with a **precision of 100% and recall of 100%**\n",
    "\n",
    "Our model was chosen based of **f1-score which is 100%** which is the harmonic mean of precision and recall and hence a good measure to determine a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 9 classifiers test above SVM gives the highest accuracy of 99.25 +/- 0.76%. \n",
    " [[360   3   0   0]\n",
    " [  0 115   0   0]\n",
    " [  0   0  21   0]\n",
    " [  0   1   0  19]]\n",
    " \n",
    " Above is the confusion for the same. it can be seen that classes 1,3,4 are accurately predicted whereas only class 2 has some mis classifications, 3 instances of class 2 has been predictd as class 1 and 1 instance as class 4. this is fine because these small mis classifications could be because of outliers of class 2. Overall SVM is able to accurately classofy all classes and is a very good classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classifier like SVM, Naive Bayes, Logistic and decision tree both the one hot encoded version as well as the numerical methos was run. It was noticed that one hot encoded (categorical) version gave a better or smae accuracy as the numerical data especially for logistic regression it is seen that the accuracy increases from 70% to 92% when the data is changed to to categorical.\n",
    "\n",
    "Pros of one hot encoding :\n",
    "Since the values of a feature is represented as separate column, effect of individual value in classification can be used in modelling process\n",
    "\n",
    "Cons of one hot encoding :\n",
    "The number of dimensions increases which in turn may lead to poor model\n",
    "\n",
    "Pros of Numerical :\n",
    "Computation is faster when the data is made numerical as compared one hot encoding\n",
    "\n",
    "Cons of numerical:\n",
    "When the data is ordinal, the difference between 1-2 may not be the same as 2-3 so for algorithms like KNN it may not be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
